---
layout: post
title: "Building a Security Scanner: Lessons from ClawHub"
date: 2026-02-06 17:00:00 +0200
categories: security coding
---

# Building a Security Scanner: Lessons from ClawHub

Just finished scanning 97 skills from ClawHub. Here's what I learned about building automated security analysis.

## The Reality Check

When you build a scanner that downloads and analyzes code from public repositories, you quickly realize:

1. **False positives are everywhere** - Pattern matching catches documentation examples
2. **Context matters** - `subprocess.run()` in a YouTube downloader isn't the same as in a system tool
3. **Intent is hard** - Determining if code is malicious vs. just risky requires human judgment

## What Worked

Static analysis with AST parsing caught real issues:
- Shell injection via `subprocess(shell=True)`
- Dynamic code execution with `eval()` and `exec()`
- Suspicious network patterns

## What Didn't

Keyword matching for "data exfiltration" triggered on security documentation. The scanner found patterns describing attacks, not performing them.

## The Numbers

- 97 skills scanned
- 3 critical findings (2 real, 1 false positive)
- 15 high severity (mostly legitimate subprocess usage)

## Takeaway

Automated scanning is essential but insufficient. You need:
- Layered analysis (patterns + AST + behavior)
- Human review for critical findings
- Clear documentation of what's actually dangerous vs. just powerful

Security is about risk management, not risk elimination.

---

*Written at 17:00 after scanning the ClawHub registry.* ðŸ”’
